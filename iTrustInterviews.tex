% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%

\setlength{\paperheight}{11in}
\setlength{\paperwidth}{8.5in}

%\documentclass[conference]{IEEEtran}
%\documentclass{acm_proc_article-sp}
\documentclass[10pt,journal,compsoc]{IEEEtran}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% Optionally save space in lists (place this command after a list environment (e.g., itemize, enumerate, description)
\newcommand{\compresslist}{
	\vspace{-1em}
	\setlength{\itemsep}{1pt}
	\setlength{\parskip}{0pt}
	\setlength{\parsep}{0pt}
}

\usepackage{flushend}

\usepackage{subfigure}
\usepackage{cite}
\usepackage{tabularx}
\usepackage[table, svgnames]{xcolor} 
\usepackage{color}
\usepackage{siunitx}
\usepackage{multirow}
\usepackage{wasysym}
\input{macros}
\usepackage{dcolumn}
\usepackage[hidelinks]{hyperref}

\newcolumntype{Y}{D..{6.4}}

%\newcommand{\blind}[1]{{\color{white}\{#1\}}}
\newcommand{\blind}[1]{#1}

\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000

%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
\begin{document}
\title{How Developers Diagnose Potential Security Vulnerabilities with Static Analysis}
% What Questions Do Developers Ask When Reasoning about the Security of Their Code? Building Tools that Answer Developers' Questions about Security Vulnerabilities?

\author{Justin~Smith, Brittany~Johnson, Emerson~Murphy-Hill, Bill~Chu, and Heather~Richter~Lipford%
		\IEEEcompsocitemizethanks{
			\IEEEcompsocthanksitem J. Smith is with North Carolina State University, Raleigh, NC 27603. E-mail: jssmit11@ncsu.edu
			\IEEEcompsocthanksitem B. Johnson is with North Carolina State University, Raleigh, NC 27603. E-mail: bijohnso@ncsu.edu
			\IEEEcompsocthanksitem E. Murphy-Hill is with North Carolina State University, Raleigh, NC 27603. E-mail: emerson@csc.ncsu.edu
			\IEEEcompsocthanksitem B. Chu is with University of North Carolina at Charlotte, Charlotte, NC 28223. E-mail: billchu@uncc.edu
			\IEEEcompsocthanksitem H. Richter Lipford is with University of North Carolina at Charlotte, Charlotte, NC 28223. E-mail: heater.lipford@uncc.edu}
		}
		
\markboth{IEEE Transactions On Software Engineering,~Vol.~XX, No.~X, MONTH~YEAR}%
{Smith \MakeLowercase{\textit{et al.}}: How Developers Diagnose Potential Security Vulnerabilities with Static Analysis}

%\affaddr{North Carolina State University}\\
%\affaddr{Raleigh, NC, USA} \\
%\email{\{jssmit11, bijohnso\}@ncsu.edu, emerson@csc.ncsu.edu}
%\alignauthor Bill Chu and Heather Richter Lipford\\
%\affaddr{University of North Carolina at Charlotte}\\
%\affaddr{Charlotte, NC, USA}\\
%\email{\{billchu, heather.lipford\}@uncc.edu}


\IEEEtitleabstractindextext{%
\begin{abstract}
%Security tools can help developers answer questions about potential vulnerabilities in their code. 
%A better understanding of the types of questions asked by developers may help toolsmiths design more effective tools.

While using security tools to resolve security defects, software developers must apply considerable effort.
Success depends on a developer's ability to interact with tools, ask the right questions, and make strategic decisions. 
To build better security tools and subsequently help developers resolve defects more accurately and efficiently, we studied the defect resolution process --- from the questions developers ask to their strategies for answering them.
%Throughout the defect resolution process, developers strategically orchestrate their 	decisions, actions, and interactions with a team.
In this paper, we report on an exploratory study with novice and experienced software developers.
We equipped them with Find Security Bugs, a security-oriented static analysis tool, and observed their interactions with security vulnerabilities in an open-source system that they had previously contributed to.
We found that they asked questions not only about security vulnerabilities, associated attacks, and fixes, but also questions about the software itself, the social ecosystem that built the software, and related resources and tools.
We describe the strategic successes and failures we observed and how future tools can leverage our findings to encourage better strategies.	
	
%For example, when participants asked questions about the source of tainted data, their tools forced them to make imperfect tradeoffs between systematic and ad hoc program navigation strategies.
%Our results have several implications for designing security tools that support developers
%by helping them answer their questions.

\end{abstract}
}


\maketitle

\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}

%Security is critical
\IEEEPARstart{S}{oftware} developers are a critical part of making software secure, a particularly important task considering security vulnerabilities are likely to cause incidents that affect company profits as well as end users~\cite{chen2002mops}.
When software systems contain security defects, developers are responsible for fixing them. 
In fact, a recent survey by Christakis and Bird found that developers cared more about security issues than other reliability issues~\cite{christakis2016developers}.

Static analysis tools, like Find Security Bugs (FSB)~\cite{FindSecurityBugs} and many others~\cite{CodeAnalysis, OWASPSCA, SecurityAnalyzers, CodeSonar, Coverity}, promise to help developers remove security defects early in the development life cycle.
These tools locate and report on potential software security vulnerabilities, such as SQL injection and cross-site scripting even before the code executes.

Unfortunately, these tools are confusing for developers to use.
Researchers cite several related reasons why these tools do not help developers resolve defects, for instance, the tools: ``may not give enough information''~\cite{johnson2013don}; produce ``bad warning messages''~\cite{christakis2016developers}; and ``miscommunicate'' with developers ~\cite{johnson2016cross}.


%Unfortunately, research suggests that developers do not use static analysis tools, despite their availability, partially because tools do not provide the information needed to resolve defects~\cite{johnson2013don}. 

%%Tools help developers with security
%To assist developers with the task of detecting and removing security defects, toolsmiths provide a variety of static analysis tools.
%One example of such a tool is Find Security Bugs (FSB)~\cite{FindSecurityBugs}, an extension of FindBugs~\cite{FindBugs}.
%x FSB locates and reports on potential software security vulnerabilities, such as SQL injection and cross-site scripting.  
%Other tools, such as CodeSonar~\cite{CodeSonar} and Coverity~\cite{Coverity}, can also be used to detect and remove potential security vulnerabilities.
%In fact, toolsmiths have created over 50, both free and commercial, static analysis tools to help developers secure their systems~\cite{CodeAnalysis, OWASPSCA, SecurityAnalyzers}.
%
%These tools provide, for instance, information about the locations of potential SQL injection vulnerabilities.
%But developers don't use them because they don't provide right information

Our work investigates this tool understanding problem by advancing our knowledge of how developers use a security-focused static analysis tool to resolve security defects, including developers' information needs, defect resolution strategies, and assumptions.
This is the first study to investigate these facets of security tool usage. 
%As we show later in this paper, developers need unique types of information while assessing security vulnerabilities, like information about attacks.

%What we did
To that end, we conducted an exploratory think-aloud study with ten developers who had contributed to iTrust~\cite{iTrust}, a security-critical Java medical records software system.
We observed each developer as they assessed potential security vulnerabilities identified by FSB. 
We operationalized developers' information needs by measuring questions --- the verbal manifestations of information needs.
Using a card sort methodology, we sorted 559 questions into 17 categories. 
We report the questions participants asked throughout our study, discuss the strategies participants used to answer questions in each category, and also describe the assumptions participants made.



%%And this work has improved the effectivness of tools
In non-security domains, work that identifies information needs has helped toolsmiths both evaluate the effectiveness of existing tools~\cite{ammar2012empirical}, and improve the state of program analysis tools~\cite{kononenko2012automatically, servant2012history, yoon2013visualization}. 
Similarly, we expect that categorizing developers' information needs while using security-focused static analysis tools will help researchers evaluate and toolsmiths improve those tools. 



%Defect resolution strategies, including their information acquisition strategies. 


%The primary contribution of this work is a categorization of questions, which researchers and toolsmiths can use to inform the design of more usable static analysis tools.

%Figure, high res, png or vector (pdf)

%%TODO Add assumption analysis to intro
%Close relationship between information needs and assumptions. 
%Assumptions can satisfy information needs. Can't figure something out? Make an assumption. short circut an investigation
%Assumptions also drive information needs. Need information to validate assumptions.
%Made an assumption? See if it's right. 
%
%Reasons to look at assumptions:
%
%1) Making incorrect assumptions causes developers to seek unnecessary information.
%This is the idea of ``going down the rabbit hole." Ex. Assume the random number generator is implemented incorrectly. Start debugging the code that comprises that module, when really it was called with the wrong parameter. Wasting developer's resources -- time.
%
%2) Incorrect assumptions not only cause developers to explore the wrong paths, but can lead them to make incorrect conclusions. Assume the code is just called from tests. Conclude it is safe.
%
%3) Correct assumptions suggest alignment between mental model and reality. 
%Proxy for measuring success.
%Given the correct assumptions, the information you seek will be relevant to the solution.

An earlier version of this work appeared as a conference paper~\cite{Smith2015Questions}. 
The contribution we presented in that paper was a categorization of questions developers asked while resolving security defects.
While that contribution explains developers' information needs, it did not explain how developers \textit{answer} those questions.
In this work, we explore how developers acquire the information they need either actively (through strategies) or passively (through assumptions).

%It focuses solely on the categorization of questions developers ask while resolving security vulnerabilities. 

Consequently, this paper elaborates on the earlier work with the following two additional contributions:

\begin{itemize}
	\item A catalog of developers defect resolution strategies, organized by the information need each strategy addresses. 
	For example, to understand how to implement a fix, participants strategically surveyed multiple sources of information, including the web, the tool's notification, and other modules in the code.
	\item A description of the common assumptions that undermined those strategies. 
	For some tasks, some participants incorrectly assumed input validation had been handled securely.
\end{itemize}

%Other stuff??
%(2) A more descriptive explanation of the study tasks in Section \ref{sec:meth}
%(3) An expanded discussion of related work in Section \ref{sec:rw}
%(4) A more concrete depiction of the notifications described in Section %\ref{structuredNotifications}


\section{Methodology}
\label{sec:meth}
We conducted an exploratory study with ten software developers. In our analysis, we extracted and categorized the questions developers asked during each study session. 
Section \ref{rqs} outlines the research questions we sought to answer. 
Section \ref{studyDesign} details how the study was designed and Sections \ref{sec:questionAnalysis}, \ref{sec:strategyAnalysis}, and \ref{sec:assumptionAnalysis} describe how we performed our three phases of data analysis.
Study materials can be found online~\cite{ExperimentalMaterials} and in the appendices.

\subsection{Research Question}
\label{rqs}
We answer the following research questions:
\begin{itemize}
	\item \textbf{RQ1}: What information do developers need while using static analysis tools to diagnose potential security vulnerabilities? 
	\item \textbf{RQ2}: What strategies do developers use to acquire the information they need?
	\item \textbf{RQ3}: What assumptions do developers make while executing these strategies?
	\end{itemize}
We measured developers' information needs (RQ1) by examining the questions they asked.
The questions that we identified are all available online~\cite{ExperimentalMaterials}.
We list several exemplary questions throughout Section \ref{sec:results} alongside the strategies developers used (RQ2) and assumptions developers made (RQ3) while answering those questions.
Where possible, we also describe how participants' strategies and assumptions led to information seeking successes or failures.


\subsection{Study Design}
\label{studyDesign}
To ensure all participants were familiar with the study environment and Find Security Bugs (FSB),
each in-person session started with a five-minute briefing section.
The briefing section included a demonstration of FSB's features and time for questions about the development environment's configuration.
During the briefing section, we informed participants of the importance of security to the application and that the software may contain security vulnerabilities.

Additionally, we asked participants to use a think-aloud protocol, which encourages  participants to verbalize their thought process as they complete a task or activity~\cite{nielsen2002getting}. 
Specifically, they were asked to: ``Say any questions or thoughts that cross your mind regardless of how relevant you think they are.''
We recorded both audio and the screen as study artifacts for data analysis.

\begin{figure}
	\subfigcapskip = 5pt
	\subfigure[Navigation]{
		\includegraphics[width=\columnwidth]{Images/Nav.png}
	}
	
	\subfigcapskip = 5pt
	\subfigure[Code]{
		\includegraphics[width=\columnwidth]{Images/Code.png}
	}
	
	\subfigcapskip = 5pt
	\subfigure[Short Notification Text]{
		\includegraphics[width=\columnwidth]{Images/BugInfo.png}
	}
	
	
	\caption{The study environment.}
	\label{fig:environment} 
\end{figure}

Following the briefing period, participants progressed through encounters with four vulnerabilities. 
Figure \ref{fig:environment} depicts the configuration of the integrated development environment (IDE) for one of these encounters.
All participants consented to participate in our study, which had institutional review board approval, and to have their session recorded using screen and audio capture software.
Finally, each session concluded with several demographic and open-ended discussion questions.



\subsubsection{Materials}
Participants used Eclipse to explore vulnerabilities in iTrust, an open source Java medical records web application that ensures the privacy and security of patient records according to the HIPAA statute~\cite{HIPAA}. 
Participants were equipped with FSB, an extended version of FindBugs.

We chose FSB because it detects security defects and compares to other program analysis tools, such as those listed by NIST,~\cite{SecurityAnalyzers} OWASP,~\cite{OWASPSCA} and WASC~\cite{CodeAnalysis}. 
Some of the listed tools may include more or less advanced bug detection features. 
However, FSB is representative of static analysis security tools with respect to its user interface, specifically in how it communicates with its users.
FSB provides visual code annotations and textual notifications that contain vulnerability-specific information.
It summarizes all the vulnerabilities it detects in a project and allows users to prioritize potential vulnerabilities based on several metrics such as bug type or severity.


\begin{table}
\centering
\caption{Participant Demographics}
\begin{tabular}{|l|l|c|S|}
\rowcolor{gray!50}
\hline
    Participant		& Job Title 						& Vulnerability 			&\multicolumn{1}{c|}{Experience} \\
    \rowcolor{gray!50}
    				&									& Familiarity				&   \multicolumn{1}{c|}{Years} \\
    \hline
    P1*			    & Student     						& \CIRCLE{}\CIRCLE{}\LEFTcircle{}\Circle{}\Circle{} 	&  4.5    \\
    \hline
    P2*			    & Test Engineer    					& \CIRCLE{}\CIRCLE{}\CIRCLE{}\Circle{}\Circle{}		&  8 		\\
    \hline
    P3 				& Development Tester       			& \CIRCLE{}\CIRCLE{}\Circle{}\Circle{}\Circle{}		&  6 	    	\\
    \hline
    P4*				& Software Developer     			& \CIRCLE{}\CIRCLE{}\Circle{}\Circle{}\Circle{}			&  6     	\\
    \hline
    P5*				& Student      						& \CIRCLE{}\CIRCLE{}\CIRCLE{}\CIRCLE{}\Circle{}			&  10 	\\
    \hline
    P6				& Student		    				& \CIRCLE{}\Circle{}\Circle{}\Circle{}\Circle{}			& 4		\\
    \hline
    P7				& Software Developer    	& \CIRCLE{}\CIRCLE{}\CIRCLE{}\CIRCLE{}\Circle{}		& 4.5         \\
    \hline
    P8				& Student	    					& \CIRCLE{}\CIRCLE{}\CIRCLE{}\Circle{}\Circle{}		& 7   \\
    \hline
    P9				& Software Consultant   	 		& \CIRCLE{}\CIRCLE{}\CIRCLE{}\Circle{}\Circle{}		& 5	  		 \\
    \hline
    P10			    & Student    						& \CIRCLE{}\CIRCLE{}\CIRCLE{}\Circle{}\Circle{}		& 8	           \\
    \hline
\end{tabular}
\label{table:participants}
\end{table}



\subsubsection{Participants}
For our study, we recruited ten software developers, five students and five professionals. 
Table~\ref{table:participants} gives additional demographic information on each of the ten participants. 
Asterisks denote previous use of security-oriented tools.
Participants ranged in programming experience from 4 to 10 years, averaging 6.3 years.
Participants also self-reported their familiarity with security vulnerabilities on a 5 point Likert scale, with a median of 3.
Although we report on experiential and demographic information, the focus of this work is to identify questions that span experience levels.
In the remainder of this paper, we will refer to participants by the abbreviations found in the participant column of the table.

We faced the potential confound of measuring participants questions about a new code base rather than measuring their questions about vulnerabilities.
To mitigate this confound, we required participants to be familiar with iTrust;
all participants either served as teaching assistants for, or completed a semester-long software engineering course that focused on developing iTrust.
This requirement also ensured that participants had prior experience using static analysis tools.
All participants had prior experience with FindBugs, the tool that FSB extends, which facilitated the introduction of FSB.

However, this requirement restricted the size of our potential participant population.
Accordingly, we used a nonprobabilistic, purposive sampling approach~\cite{guest2006many}, which typically yields fewer participants, but gives deeper insights into the observed phenomena.
To identify eligible participants, we recruited via personal contacts, class rosters, and asked participants at the end of the study to recommend other qualified participants.
Although our study involved only ten participants, we reached saturation~\cite{glaser2009discovery} rather quickly; 
no new question categories were introduced after the fourth participant.
%ideographic, nomethethic, or typical size, grounded theory
%Typical grounded theory analysis involves X, Y, Z. Other work has reached saturation at X Participants. 

%

%This format has fewer participants but gives deeper insight.

%Since extracting data from each session required intensive analysis, we ceased recruitment when we determined that we had reached saturation~\cite{glaser2009discovery} and few new questions were emerging from each additional session.

  
\subsubsection{Tasks}
%TODO Expand on these bad boys
First we conducted a preliminary pilot study ($n = 4$), in which  participants spent approximately 10 to 15 minutes with each task and showed signs of fatigue after 60 minutes.
To reduce the effects of fatigue, we asked each participant to assess four vulnerabilities. 
We do not report on data collected from this preliminary study.

When selecting tasks, we ran FSB on iTrust and identified 118 potential security vulnerabilities across three topics.
To increase the diversity of responses, we selected tasks from mutually exclusive topics, as categorized by FSB.
For the fourth task, we added a SQL injection vulnerability to iTrust by making minimal alterations to one of the database access objects.
Our alterations preserved the functionality of the original code and were based on examples of SQL injection found on OWASP~\cite{OWASP} and in open-source projects.
We chose to add a SQL injection vulnerability, because among all security vulnerabilities, OWASP ranks injection vulnerabilities as the most critical web application security risk.

For each task, participants were asked to assess code that ``may contain security vulnerabilities'' and ``justify any proposed code changes.''
Table \ref{table:vulnerabilities} summarizes each of the four tasks and the remainder of this section provides more detail about each task.\\

\noindent\textbf{Task 1} \\
The method associated with Task 1 opens a file, reads its contents, and executes the contents of the file as SQL queries against the database. 
Before opening the file, the method does not escape the filepath, potentially allowing arbitrary SQL files to be executed.
However, the method is only ever executed as a utility from within the unit test framework. The mean completion time for this task was 14 minutes and 49 seconds.

\noindent\textbf{Task 2} \\
The method associated with Task 2 is used to generate random passwords when a new application user is created. FSB warns \CodeIn{Random} should not be used in secure contexts and instead suggests using \CodeIn{SecureRandom}. \CodeIn{SecureRandom} is a more secure alternative, but its use comes with a slight performance trade-off. 
The mean completion time for this task was 8 minutes and 52 seconds.

\noindent\textbf{Task 3} \\
The method associated with Task 3 reads several improperly validated string values from a form. 
These values are eventually redisplayed on the web page exposing the application to a cross site scripting attack. 
The mean completion time for this task was 13 minutes and 19 seconds.

\noindent\textbf{Task 4} \\
In the method associated with Task 4, a SQL Statement object is created using string interpolation, which is potentially vulnerable to SQL injection. FSB recommends using  \CodeIn{PreparedStatements} instead. The mean completion time for this task was 8 minutes.
\\

\begin{table*} 
	\centering
	\caption{Four vulnerability exploration tasks}
	\begin{tabularx}{\textwidth}{|l|X|l|}
		\rowcolor{gray!50}
		\hline
		Vulnerability				& Short Description													& Severity Rank 	\\
		\hline	
		Potential Path Traversal	& An instance of java.io.File is created to read a file.     			& ``Scary''	    \\
		\hline
		Predictable Random			& Use of java.util.Random is predictable. 								& ``Scary''		\\
		\hline
		Servlet Parameter 			& The method getParameter returns a String value that is controlled by the client.			& ``Troubling''	\\
		\hline
		SQL Injection				& [Method name] passes a non-constant String to an execute method on an SQL statement.     	& ``Of Concern'' \\
		\hline
	\end{tabularx}
	\label{table:vulnerabilities}
\end{table*}

\subsection{Data Analysis --- Questions}
\begin{figure*}
	\centering
	\includegraphics[trim={0 0 0 3mm},clip, width=\textwidth]{Images/QuestionMerging}
	\caption{Question merging process}
	\label{fig:merging} 
\end{figure*}

\label{sec:questionAnalysis}
To analyze the data, we first transcribed all the audio-video files using oTranscribe~\cite{OTranscribe}.
Each transcript, along with the associated recording, was analyzed by two of the authors for questions. 
The two question sets for each session were then iteratively compared against each other until the authors reached agreement on the question sets. 
In the remainder of this section, we will detail the question extraction process and question sorting processes, including the criteria used to determine which statements qualified as questions.
\subsubsection{Question Criteria}
Drawing from previous work on utterance interpretation~\cite{letovsky1987cognitive}, we developed five criteria to assist in the uniform classification of participant statements. 
A statement was coded as a question only if it met one of the following criteria:
\\
\begin{itemize}
\compresslist	
\item \textbf{The participant explicitly asks a question.}
\\ Ex: \textit{Why aren't they using \CodeIn{PreparedStatements}?}
\item \textbf{The participant makes a statement and explores the validity of that statement.}
\\ Ex: \textit{It doesn't seem to have shown what I was looking for. Oh, wait! It's right above it...}
\item \textbf{The participant uses key words such as, ``I assume,'' ``I guess,'' or ``I don't know.''}
\\ Ex: \textit{I don't know that it's a problem yet.}
\item \textbf{The participant clearly expresses uncertainty over a statement.}
\\ Ex: \textit{Well, it's private to this object, right?}
\item \textbf{The participant clearly expresses an information need by describing plans to acquire information.}
\\ Ex: \textit{I would figure out where it is being called.}

\end{itemize}




\subsubsection{Question Extraction}
To make sure our extraction was exhaustive, the first two authors independently coded each transcript using the criteria outlined in the previous section.
When we identified a statement that satisfied one or more of the above criteria, we marked the transcript, highlighted the participant's original statement, and clarified the question being asked.
Question clarification typically entailed rewording the question to best reflect the information the participant was trying to acquire.
From the ten sessions, the first coder extracted 421 question statements; the other coder extracted 389. 

It was sometimes difficult to determine what statements should be extracted as questions; the criteria helped ensure both authors only highlighted the statements that reflected actual questions. 
Figure \ref{fig:merging} depicts a section of the questions extracted by both authors from P8 prior to review.


\subsubsection{Question Review}
To remove duplicates and ensure the validity of all the questions, each transcript was reviewed jointly by the two authors who initially coded it.
During this second pass, the two reviewers examined each question statement, discussing its justification based on the previously stated criteria.
The two reviewers merged duplicate questions, favoring the wording that was most strongly grounded in the study artifacts.
This process resulted in a total of 559 questions.

Each question that was only identified by one author required verification.
If the other author did not agree that such a question met at least one of the criteria, the question was removed from the question set and counted as a disagreement.
The reviewers were said to agree when they merged a duplicate or verified a question. Depending on the participant, inter-reviewer agreement ranged from 91\% to 100\%. Across all participants, agreement averaged to 95\%.
The agreement scores suggest that the two reviewers consistently held similar interpretations of the question criteria.

It is also important to note that participants' questions related to several topics in addition to security. 
We discuss the questions that are most closely connected to security in Sections \ref{pupa}, \ref{eui}, and \ref{bsr}.
Although our primary focus is security, we are also interested in the other questions that participants posed, as those questions often have security implications.
For example, researchers have observed that developers ask questions about data flow, like \emph{What is the original source of this data}, even outside security~\cite{latoza2010hard}.
However, in a security context, this question is particularly important, because potentially insecure data sources often require special handling to prevent attacks.


\subsubsection{Question Sorting}
To organize our questions and facilitate discussion, we performed an \textit{open} card sort~\cite{hudson2013sorting}. 
Card sorting is typically used to help structure data by grouping related information into categories. 
In an \textit{open} sort, the sorting process begins with no notion of predefined categories. 
Rather, sorters derive categories from emergent themes in the cards. 

We performed our card sort in three distinct stages: clustering, categorization, and validation.
In the first stage, we formed question clusters by grouping questions that identified the same information needs. 
In this phase we focused on rephrasing similar questions and grouping duplicates.
For example, P1 asked, \textit{Where can I find information related to this vulnerability?} P7 asked, \textit{Where can I find an example of using \CodeIn{PreparedStatements}?} and P2 asked, \textit{Where can I get more information on path traversal?} 
Of these questions, we created a question cluster labeled \textit{Where can I get more information?}
At this stage, we discarded five unclear or non pertinent questions and organized the remaining 554 into 155 unique question clusters.

In the second stage, we identified emergent themes and grouped the clusters into categories based on the themes. 
For example, we placed the question \textit{Where can I get more information?} into a category called \emph{\textbf{Resources/Documentation}}, along with questions like \textit{Is this a reliable/trusted resource?} and \textit{What information is in the documentation?} 
Table~\ref{table:categories} contains the 17 categories along with the number of distinct clusters each contains. 

To validate the categories that we identified, we asked two independent researchers to sort the question clusters into our categories. 
Rather than sort the entire set of questions, we randomly selected 43 questions for each researcher to sort.
The first agreed with our categorization with a Cohen's Kappa of $\kappa = .63$. 
Between the first and second researcher we reworded and clarified some ambiguous questions. The second researcher exhibited greater agreement ($\kappa = .70$). 
These values are within the $.60 - .80$ range, indicating substantial agreement~\cite{Landis1977agreement}.

\subsection{Data Analysis --- Strategies}
%TODO Address RG comments here
\label{sec:strategyAnalysis}
%This analysis took place after everything in Questions analysis
To answer RQ2 the first author performed two additional passes through the transcripts and recordings. 
%Pass 1
In the first pass, we focused on identifying each participant's defect resolution strategy for each task. 
We define a defect resolution strategy as all the actions a developer takes to validate and resolve a defect. 
Such actions include invoking additional tools, modifying the source code, and searching the web.
%Granularity? Is an action a click? Sometimes. 

To represent these defect resolution strategies we drew from the notion of attack trees~\cite{attackTrees}. 
Attack trees encode the actions an attacker could take to exploit a system, including the idea that he may combine multiple actions to achieve a higher-level goal. 
Much like attack trees, our representation organizes actions hierarchically.
We refer to this representation as a strategy tree.
Whereas attack trees describe an attacker's actions, we use strategy trees to represent the hierarchical set of actions a developer takes to resolve a security defect. 
Figure \ref{fig:description} depicts an example strategy tree.
To identify participants' actions and construct the strategy trees, we used the screen recordings and participants' think-aloud verbalizations. 
%how do you decide what depth to place an action at.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{"Images/descriptionFormat.png}
	\caption{Example strategy tree for a null dereference defect. }
	\label{fig:description} 
\end{figure}



%Pass 2 Succsess/failure Also information needs annotation
During the second pass we added annotations to each strategy tree. 
As depicted in Figure \ref{fig:description} (lines prefixed with $+$/$-$), we annotated the trees whenever an action led to a success or a failure. 
To best understand which strategies contributed to success, we measured success/failure as granularly as possible.
Rather than annotating the entire tree as successful or not, we annotated the sub-strategies that compose the tree.
Participants could succeed with some strategies while failing with others.
For example, participants could succeed in locating relevant information, but fail to interpret it correctly. 
Some sub-strategies were not observably successful/failure-inducing and were, therefore, not annotated. 

%Second annotation Link questions and strategies

\subsection{Data Analysis --- Assumptions}
\label{sec:assumptionAnalysis}
%Motivation
%Annecdote Help them unask the question
 
%Methodology
To answer RQ3, we identified participants' assumptions and analyzed each assumption to determine if it was correct.
Participants likely made many assumptions implicitly. 
%How often do developers make assumptions and to what extent are those assumptions correct.
Because such implicit assumptions are pervasive~\cite{fairclough2003analysing}, it would be intractable to identify them all. 
For example, they may have implicitly assumed the Eclipse environment was configured correctly and all the relevant source files were accessible.
Instead of speculating about all of these assumptions, we only consider the assumptions participants explicitly stated.

%Tried to enumerate implicit assumptions, but so . Infinite number of assumptions them. Give plausible examples... 
%
To identify the explicit assumptions participants made, we searched the transcripts for keywords.
To derive the search set, we started with the following base words: \textit{assume}, \textit{presume}, \textit{reckon}, \textit{believe}, and \textit{guess}.
Next, we applied lemmatisation to identify all the inflected forms of these words, such as \textit{hypothesize}, \textit{speculate}, \textit{suppose}, etc. 
%Lemmatisation - http://wordnetweb.princeton.edu/perl/webwn
Finally, we searched the transcripts for the stems of all the words identified by the lemmatisation process.
This search process returned some false-positives. 
For example, one participant referred to the interviewer's assumptions rather than making an assumption of his own asking, ``Am I \textit{assumed} to have some prior knowledge?''
To filter only the assumptions participants made about the task or the code, the first author inspected each search result.

After determining the result was an assumption, we evaluated its correctness.
For example, one participant's assumed an external library was implemented securely. 
We determined this assumption was incorrect by locating a vulnerability in the library using the common vulnerability and exposures database.\footnote{\url{cve.mitre.org}}


\begin{table*} 
	\centering
	\caption{Organizational Groups and Emergent Categories}
	\begin{tabularx}{\textwidth}{|l|X|r|c|}
		\rowcolor{gray!50}
		\hline
		Group											& Category										& Clusters		& Location in Paper	  	\\
		\hline			
		\multirow{4}{*}{Vulnerabilities, Attacks, and Fixes}
		& Preventing and Understanding Potential Attacks	& 11     		& Section~\ref{pupa}		\\
		
		& Understanding Alternative Fixes and Approaches	& 11     		& Section~\ref{uafa}	\\
		
		& Assessing the Application of the Fix				& 9     		& Section~\ref{aaf}				\\
		
		& Relationship Between Vulnerabilities							& 3     		& Section~\ref{rbb}			\\
		\hline
		\multirow{6}{*}{Code and the Application}	
		& Locating Information 								& 11      		& Section~\ref{li}		\\
		
		& Control Flow and Call Information					& 13     		& Section~\ref{cf}	\\
		
		& Data Storage and Flow								& 11     		& Section~\ref{dsf}  	\\
		
		& Code Background and Functionality	 				& 17     		& Section~\ref{cbf}			\\
		
		& Application Context/Usage										& 9     		& Section~\ref{acu}			\\
		
		& End-User Interaction											& 3     		& Section~\ref{eui}		\\
		\hline	
		\multirow{3}{*}{Individuals}	
		& Developer Planning and Self-Reflection						& 14    		& Section~\ref{dpr}		\\
		
		& Understanding Concepts										& 6 			& Section~\ref{uc}			\\
		
		& Confirming Expectations					 					& 1				& Section~\ref{ce}  \\
		\hline
		\multirow{4}{*}{Problem Solving Support}
		
		& Resources and Documentation									& 10     		& Section~\ref{rd}		\\
		
		
		
		& Understanding and Interacting with Tools						& 9     		& Section~\ref{uit}			\\
		
		& Vulnerability Severity and Rank								& 4     		& Section~\ref{bsr}		\\
		
		& Notification Text												& 3     		& Section~\ref{em}		\\
		
		\hline	
		& Uncategorized													& 10    		&			 \\
		\hline
	\end{tabularx}
	\label{table:categories}
\end{table*}



\section{Results}
\label{sec:results}
\subsection{Interpreting the Results}

In the next four sections, we discuss our study's results using the categories we described in Section \ref{sec:questionAnalysis}.
Due to their large number, we grouped the categories to organize and facilitate discussion about our findings. 
Table~\ref{table:categories} provides an overview of these groupings.

For each category, we selected several questions to discuss. A full categorization of questions can be found online along with the full descriptions of participants strategies~\cite{ExperimentalMaterials}.
The numbers next to the category titles denote the number of participants that asked questions in that category and the total number of questions in that category --- in parenthesis and brackets respectively. Similarly, the number in parenthesis next to each question marks the number of participants that asked that question.

When discussing the questions participants asked for each category, we will use phrases such as ``\emph{X} participants asked \emph{Y}.''
Note that this work is exploratory and qualitative in nature.
Though we present information about the number of participants who ask specific questions, the reader should not infer any quantitative generalizations.

The structure of most results categories consists of four parts: an overview of the category, several of the questions we selected, a discussion of those questions (RQ1), and a discussion of how participants answer the questions in that category (RQ2 and RQ3).
Some sections contain less discussion than others either because participants' intentions in asking questions were unclear, or participants asked questions without following up or attempting to answer them at all. 

To answer RQ2, we describe developers' defect resolution strategies.
These strategies for answering individual questions often overlap, especially within a given category.
Accordingly, to present a coherent discussion and avoid duplication, we discuss strategies for each category rather than for each question.

In this section we also describe participants' correct and incorrect assumptions (RQ3) as well as elaborate on how those assumptions contributed to defect resolution.
While performing their tasks, participants made different types of assumptions. 
Overall, we observed 73 total assumptions --- 27 incorrect and 46 correct. 
We identified assumptions across all participants, except for P3, who may have made assumptions without stating them explicitly.
Additionally, participants stated at least one assumption during each task.
%


\subsection{Vulnerabilities, Attacks, and Fixes}
\label{sec:results-vaf}

% next paragraph, go into description of first group 
%%%%%%%%%%%% Preventing and Understanding Potential Attacks 
\subsubsection{Preventing and Understanding Attacks (10)\{11\}}
%#11.X
\label{pupa}
Unlike other types of code defects that may cause code to function unexpectedly or incorrectly, security vulnerabilities expose the code to potential attacks. For example, the Servlet Parameter vulnerability (Table~\ref{table:vulnerabilities}) introduced the possibility of SQL injection, path traversal, command injection, and cross-site scripting attacks.
\\

\noindent\emph{Is this a real vulnerability? (7)} \\
\emph{What are the possible attacks that could occur? (5)} \\
\emph{Why is this a vulnerability? (3)} \\
\emph{How can I prevent this attack? (3)} \\
\emph{How can I replicate an attack to exploit this vulnerability? (2)} \\
\emph{What is the problem (potential attack)? (2)} 
\\

Participants sought information about the types of attacks that could occur in a given context.
To that end, five participants asked, \textit{What are the possible attacks that could occur?}
For example, within the first minute of his analysis P2 read the notification about the Path Traversal vulnerability and stated, ``I guess I'm thinking about different types of attacks.''
Before reasoning about how a specific attack could be executed, he wanted to determine which attacks were relevant to the notification.

Participants also sought information about specific attacks from the notification, asking how particular attacks could exploit a given vulnerability.
Participants hypothesized about specific attack vectors, how to execute those attacks, and how to prevent those attacks now and in the future.
Seven participants, concerned about false positives, asked the question, \textit{Is this a real vulnerability?} 
To answer that question, participants searched for hints that an attacker could successfully execute a given attack in a specific context. 
For example, P10 determined that the Predictable Random vulnerability was ``real'' because an attacker could deduce the random seed and use that information to determine other users' passwords. 

\textbf{Strategies and Assumptions:}
Participants used various strategies to answer questions about attacks.
When available, participants read FSB's vulnerability information. 
When FSB did not provide sufficient information, participants turned to the web, searching on sites like Google and StackOverflow. 

These strategies for getting information about different types of attacks were prone to two types of failures. 
First, because web search engines were not fully aware of participants' programming contexts, they returned information about a superset of the relevant attacks.
For example, P2 searched for attacks that exploit unvalidated input vulnerabilities.
Searching the web returns results about cross site scripting attacks, injection attacks, and buffer overflow attacks. 
However, due to Java's automatic array bounds checking, buffer overflow attacks are not feasible in the vast majority of Java programs, including iTrust.
Devoting more effort to buffer overflow attacks would have distracted P2 from the other more relevant attacks. 


Secondly, by executing these strategies some participants erroneously considered only a subset of the possible attacks. 
This failure was especially evident for the Servlet Parameter vulnerability, where a cross site scripting attack was feasible, but a SQL injection attack was not. 
Some participants correctly determined the data was sanitized before reaching the database, dismissed SQL injection, and prematurely concluded the vulnerability was a false positive.
By failing to consider cross site scripting attacks, participants overlooked the program path that exposed a true attack.

%Some Find Security Bugs notifications attempt to provide developers with the means to answer some of these questions by providing links to relevant information. 
%Many of the links provided linked to information regarding why the code may be broken, however, do not provide information to improve understanding of what the potential attacks are. 
%Some of the questions, such as \textit{How do I find out if this is a real vulnerability?}, may not be as simple to answer by providing a link. 
%This kind of question may require triangulation of information; some information from the web on the vulnerability itself and the potential attacks, and some information from fellow developers who may better understand the likelihood the bug is a vulnerability in their system. 
%One way tools can help is by providing easy access to the top web resources and developers to use when assessing the vulnerability; many of our participants preferred StackOverflow as a resource and a degree of knowledge model, like the one proposed by Fritz and his colleagues, could provide the developers most familiar with the code~\cite{fritz2010degree}.

%%%%%%%%%%%% Understanding Alternative Fixes

\subsubsection{Understanding Alternative Fixes and Approaches (8)\{11\}}\label{uafa}
%#7.X

When resolving security vulnerabilities, participants explored alternative ways to achieve the same functionality more securely.
For example, while evaluating the potential SQL Injection vulnerability, participants found resources that suggested using the \CodeIn{PreparedStatement} class instead of Java \CodeIn{Statement} class. 
\\

\noindent\emph{Does the alternative function the same as what I'm currently using? (6)} \\
\emph{What are the alternatives for fixing this? (4)} \\
\emph{Are there other considerations to make when using the alternative(s)? (3)} \\
\emph{How does my code compare to the alternative code in the example I found? (2)} \\
\emph{Why should I use this alternative method/approach to fix the vulnerability? (2)} 
\\
 
%The developer could attempt to apply the new fix or approach, but the data we report in Section~\ref{aaf} suggests developers also have questions about this process that make it difficult to quickly and effectively complete.
%SAVE THIS CONNECTION FOR LATER
Some notifications, including those for the SQL Injection and Predictable Random vulnerabilities, explicitly offered alternative fixes. 
In other cases, participants turned to a variety of sources, such as StackOverflow, official documentation, and personal blogs for alternative approaches.
 
Three participants specifically cited StackOverflow as a source for alternative approaches and fixes.
P7 preferred StackOverflow as a resource, because it included real-world examples of broken code and elaborated on why the example was broken.
Despite the useful information some participants found, often the candidate alternative did not readily provide meta-information about the process of applying it to the code. 
For example, P9 found a suggestion on StackOverflow that he thought might work, but it was not clear if it could be applied to the code in iTrust.

While attempting to assess the Servlet Parameter vulnerability, P8 decided to explore some resources on the web and came across a resource that appeared to be affiliated with OWASP~\cite{OWASP}. 
Because he recognized OWASP as ``the authority on security,'' he clicked the link and used it to make his final decision regarding the vulnerability. 
It seemed important to P8 that recommended approaches came from trustworthy sources.


\textbf{Strategies and Assumptions:}
Participants' strategies for acquiring information about alternative fixes centered around three information sources --- FSB, the web, and other modules in the code. 
Even when FSB informed participants about a specific alternative, participants sought supplementary information from the other two external sources.

For example, during Task 4, FSB suggested using \texttt{PreparedStatements}. 
In search of information about \texttt{PreparedStatements'} syntax, participants navigated to the project's related code modules they suspected would contain \texttt{PreparedStatements}.
Participants largely found examples from these related modules helpful, because they were easy to translate back to the original method.

For Task 2, participants similarly sought examples of \texttt{SecureRandom}, but were ultimately less successful.
Unaware that the project contained examples of \texttt{SecureRandom}, in this case, participants turned to online resources.
Although some participants understood the relevant online API documentation, others struggled to compare the online documentation to the original method.

%After determining which alternatives were available and before committing to a particular alternative, participants assessed the applicability of each option.
%Also understanding own code and how it compared with online examples. Juxtaposition. Ensure alt implements all methods (secure random)
%\begin{itemize}
%	\item (Secure Random)
%	\item (already say this in this section, but)  participants turned to a variety of sources, such as StackOverflow, official documentation, and personal blogs for information about alternative approaches.
%	\item also looked elsewhere in the code
%	\item ** Looked elsewhere in the code for prepared statement (found PS code examples in the project helpful!), but not secure random even though SecureRandom is used elsewhere in the project. 
%\end{itemize}

%One way a tool might help developers determine the changes, if any, they should making would be by noting other places in the code the alternative under  consideration has been used, if they exist. 

%The tool could then potentially use speculative analysis, which is used by tools like \textsc{Quick Fix Scout}, to present trade-offs of using the suggested fix or keeping the code as it is~\cite{mucslu2012speculative}.
%GOOD POINTS ABOVE NOT SURE HOW THEY FIT WITH STORY


%If the developer, or other developers of the code, have not used the alternative before, the tool could borrow behavior or design principles from \textsc{Whyline} by allowing developers to ask questions about the code in relation to the suggested approach~\cite{ko2004designing}. 



%%%%%%%%%%%% Assessing Application % % % % % % % % % % % % % % % % % % % % % % % %

\subsubsection{Assessing the Application of the Fix (9)\{9\}}\label{aaf}
%#10.X

Once participants had identified an approach for fixing a security vulnerability (Section \ref{uafa}), they asked questions about applying the fix to the code.
For example, while considering the use of \CodeIn{SecureRandom} to resolve the Predictable Random vulnerability, participants questioned the applicability of the fix and the consequences of making the change. 
The questions in this category differ from those in \emph{\textbf{Understanding Alternative Fixes and Approaches}} (Section \ref{uafa}). 
These questions focus on the process of applying  and reasoning about a given fix, rather than identifying and understanding possible fixes.
\\

\noindent\emph{Will the notification go away when I apply this fix? (5)} \\
\emph{How do I use this fix in my code? (4)} \\
\emph{How do I fix this vulnerability? (4)} \\
\emph{How hard is it to apply a fix to this code? (3)} \\
\emph{Is there a quick fix for automatically applying a fix? (2)} \\
\emph{Will the code work the same after I apply the fix? (2)} \\
\emph{What other changes do I need to make to apply this fix? (2)} 
\\

 
When searching for approaches to resolve vulnerabilities, participants gravitated toward fix suggestions provided by the notification.
As noted above, the notifications associated with the Predictable Random vulnerability and the SQL Injection vulnerability both provided fix suggestions.
All participants proposed solutions that involved applying one or both of these suggestions. 
Specifically, P2 commented that it would be nice if all the notifications contained fix suggestions.

However, unless prompted, none of the participants commented on the disadvantages of using fix suggestions.
While exploring the Predictable Random vulnerability, many participants, including P1, P2, and P6, decided to use \CodeIn{SecureRandom} without considering any alternative solutions, even though the use of that suggested fix reduces performance.
It seems that providing suggestions without discussing the associated trade-offs appeared to reduce participants' willingness to think broadly about other possible solutions. 


\textbf{Strategies and Assumptions:}
Although participants were not asked to make any modifications to the code, they did describe their strategies for applying and assessing fixes.
Many participants looked for ways to apply fixes automatically.
However, none of the FSB notifications included quick fixes.
Still, some participants unsuccessfully attempted to apply quick fixes by clicking on various interface elements.

To assess whether the fix had been applied correctly, participants commonly described one particular heuristic. P1, for instance, would make the change and simply ``see if the bug [icon] goes away." 
This strategy typically ensures the original vulnerability gets fixed, but fails when the fix introduces new defects.

%\item One proposed unnecessary changes, another proposed changes that would introduce another error

%%%%%%%%%%%% Relationship Between Vulnerabilities

\subsubsection{Relationship Between Vulnerabilities (4)\{3\}}\label{rbb}
%#12.X

Some participants asked questions about the connections between co-occurring vulnerabilities and whether similar vulnerabilities exist elsewhere in the code. 
For example, when participants reached the third and fourth vulnerabilities, they began speculating about the similarities between the vulnerabilities they inspected.
\\

\noindent\emph{Are all the vulnerabilities related in my code? (3)} \\
\emph{Does this other piece code have the same vulnerability as the code I'm working with? (1)} 
\\

\textbf{Strategies and Assumptions:}
Participants asked a few passing questions about the relationships between vulnerabilities, but were not explicitly asked to relate the vulnerabilities to each other across tasks. 
As a result, we did not observe the emergence of any predominant strategies or assumptions in this category.

%\begin{itemize}
%\item Only one occurrence. 
%P3 for Task 3 incorrectly guessed all the nearby defects were the same (wrong because some did not need sanitation).
%Otherwise, nothing more general to talk about here.
%
%Participants' strategies were to assume all the notifications were related or the same. 
%\end{itemize}


\subsection{Code and the Application}
\label{sec:results-ca}
% description of what categories fall into this group
%%%%%%%%%%%% Locating Information
\subsubsection{Locating Information (10)\{11\}}\label{li}
%#9.X

Participants asked questions about locating information in their coding environments.
In the process of investigating vulnerabilities, participants searched for information across multiple classes and files.
Unlike Sections \ref{cf} and \ref{dsf}, questions in this category more generally refer to the process of locating information, not just about locating calling information or data flow information.
\\

\noindent\emph{Where is this used in the code? (10)} \\
\emph{Where are other similar pieces of code? (4)} \\
\emph{Where is this method defined? (1)} 
\\

All ten participants wanted to locate where defective code and tainted values were in the system. 
Most of these questions occurred in the context of assessing the Predictable Random vulnerability.
Specifically, participants wondered where the potentially insecure random number generator was being used and whether it was employed generate sensitive data like passwords.

%Where is similar code?
In other cases, while fixing one method, four participants wanted to find other methods that implemented similar functionality.
They hypothesized that other code modules implemented the same functionality using more secure patterns. 
For example, while assessing the SQL Injection vulnerability, P2 and P5 both wanted to find other modules that created SQL statements.
All participants completed this task manually by scrolling through the package explorer and searching for code using their knowledge of the application.



\textbf{Strategies and Assumptions:}
%8 Participants scrolled (P2 - P9) "unassisted search"
For the majority of participants, scrolling through the source file was a key component of their strategies for locating information.
As Robillard and colleagues observed, such unstructured navigation may signal ineffectiveness~\cite{robillard2004effective}.
Eclipse provides many tools designed to help users locate specific types of information.
For example, \textsc{Open Declaration} locates method declarations, \textsc{find references} locates references.
More generally Eclipse provides a customizable \textsc{Search} tool for locating other information.
Despite the availability of such dedicated tools from the start, many participants first scrolled through the package explorer and open files, failed to find the information they needed, then switched to using tools. 


%%%%%%%%%%%% Control Flow/Call Information

\subsubsection{Control Flow and Call Information (10)\{13\}}\label{cf}
%#5.x

Participants sought information about the callers and callees of potentially vulnerable methods.
\\

\noindent\emph{Where is the method being called? (10)} \\
\emph{How can I get calling information? (7)} \\
\emph{Who can call this? (5)} \\
\emph{Are all calls coming from the same class? (3)} \\
\emph{What gets called when this method gets called? (2)}
\\

Participants asked some of these questions while exploring the Path Traversal vulnerability.
While exploring this vulnerability, many participants eventually hypothesized that all the calls originated from the same test class, therefore were not user-facing, and thus would not be called with tainted values.
Three participants explicitly asked, \textit{Are all calls coming from the same class?} 
In fact, in this case, participants' hypotheses were partially correct. 
Tracing up the call chains, the method containing the vulnerability was called from multiple classes, however those classes were all contained within a test package.
Even though all participants did not form this same hypothesis, all ten participants wanted call information for the Path Traversal Vulnerability, often asking the question, \textit{Where is this method being called?} 

 
\textbf{Strategies and Assumptions:}
Participants used various strategies to obtain information about control flow.
The most basic strategy was simply skimming the file for method calls, which was error-prone because participants could easily miss calls.
Other participants used Eclipse's \textsc{mark occurrences} tool (code highlighting in Figure \ref{fig:environment}), which, to a lesser extent, was error-prone for the same reason. 
Further, it only highlighted calls within the current file.

Participants additionally employed Eclipse's \textsc{find} tool, which found all occurrences of a method name, but there was no guarantee that strings returned referred to the same method.
Also, it returned references that occurred in dead code or comments.
Alternatively, Eclipse's \textsc{find references} tool identified references to a single method.
Eclipse's \textsc{call hierarchy} tool enabled users to locate calls and traverse the project's entire call structure.
That said, it only identified explicit calls made from within the system. 
If the potentially vulnerable code was called from external frameworks, \textsc{call hierarchy} would not alert the user.

%\begin{itemize}
%	\item Discussion of strategies already in this section
%	\item Also comes up in the flow navigation section
%	
%\end{itemize}
%

%%%%%%%%%%%% Data Storage 

\subsubsection{Data Storage and Flow (10)\{11\}}\label{dsf}
%#3.X

Participants often wanted to better understand data being collected and stored: where it originated and where it was going. 
For example, participants wanted to determine whether data was generated by the application or passed in by the user. 
Participants also wanted to know if the data touched sensitive resources like a database.
Questions in this category focus on the application's data --- how it is created, modified, or used --- unlike the questions in Section \ref{cf} that revolve around call information, essentially the paths through which the data can travel.
\\

\noindent\emph{Where does this information/data go? (9)} \\
\emph{Where is the data coming from? (5)} \\
\emph{How is data put into this variable? (3)} \\
\emph{Does data from this method/code travel to the database? (2)} \\
\emph{How do I find where the information travels? (2)} \\
\emph{How does the information change as it travels through the programs? (2)} 
\\

 
Participants asked questions about the data pipeline while assessing three of the four vulnerabilities, many of these questions arose while assessing the Path Traversal vulnerability. 


\textbf{Strategies and Assumptions:}
While exploring this vulnerability, participants adapted tools such as the \textsc{call hierarchy} tool to also explore the program's data flow. 
As we discussed in \emph{Control Flow and Call Information}, the \textsc{call hierarchy} tool helped participants identify methods' callers and callees.
Specifically, some participants used the \textsc{call hierarchy} tool to locate methods that were generating or modifying data.
Once participants identified which methods were manipulating data, they manually searched within the method for the specific statements that could modify or create data.
They relied on manual searching, because the tool they were using to navigate the program's flow, \textsc{call hierarchy}, did not provide information about which statements were modifying and creating data.

Some participants failed because they used aggregation strategies, rather than tracing individual data elements.
This was particularly evident for Task 3, where 12 variables were aggregated in a form object.
By tracing individual variables, some participants uncovered the incorrect validation function. 
Others, like P6, grew tired of tracing each variable and instead considered the form as a whole.
As a result, he overlooked the validation function and incorrectly concluded the vulnerability was a false positive.

Rather than investigate, participants also made assumptions about where data comes from, whether it be from a user or hard-coded test data.
For Task 1, P1 incorrectly assumed data was passed in from a user.
He followed up on this weakly-held assumption by further investigating the origin of the data.
His successful investigation strategy, which included him using the \textsc{call hierarchy} tool, led him to correct his initial assumption and resolve the defect correctly.


%begin{itemize}
%	\item Most relevant to task 3. 
%	\item Rather than trace individual pieces of data used an aggregation strategy.
%
%	\item P7 struggled with this task, without a good strategy to see how the data was used he proposed adding validation code (even though it already existed)
%	
%\end{itemize}
%


%%%%%%%%%%%% Code Background

\subsubsection{Code Background and Functionality (9)\{17\}}
%#8.X

\label{cbf}
Participants asked questions concerning the background and the intended function of the code being analyzed. 
The questions in this category differ from those in Section \ref{acu} because they focus on the lower-level implementation details of the code.
\\

\noindent\emph{What does this code do? (9)} \\
\emph{Why was this code written this way? (5)} \\
\emph{Why is this code needed? (3)} \\
\emph{Who wrote this code? (2)} \\
\emph{Is this library code? (2)} \\
\emph{How much effort was put into this code? (1)}
\\

Participants were interested in what the code did as well as the history of the code.
For example, P2 asked about the amount of effort put into the code to determine whether he trusted that the code was written securely.
He explained, ``People were rushed and crunched for time, so I'm not surprised to see an issue in the servlets.'' 
Knowing whether the code was thrown together haphazardly versus reviewed and edited carefully might help developers determine if searching for vulnerabilities will likely yield true positives.


\textbf{Strategies and Assumptions:}
%System has changed and not responsible for all modules
To answer questions in this category, participants relied primarily on their prior knowledge of the system.
We observed relatively few instances where participants executed additional strategies, such as looking at version control information or system documentation, to substantiate their existing knowledge. 
This strategy, or lack thereof, was susceptible to failures when participants overestimated their knowledge of the system.
For example, while assessing the Path Traversal vulnerability, P2 incorrectly assumed that the methods in the DBBulder module were only called during development and deployment when iTrust first starts up.

Participants also sought information about external libraries and commonly made assumptions about these external libraries, their correctness, and their functionality.
Some assumptions centered around the proper usage of an external library. 
For instance, while skimming \CodeIn{SecureRandom}'s documentation during Task 2, P8 incorrectly assumed \CodeIn{SecureRandom} does not provide a \CodeIn{nextInt} method.
Based on that assumption, P8 proposed a workaround that was valid, but duplicated the functionality \CodeIn{nextInt} already provided.
%citation for readability?
Other assumptions pertained to the security of external libraries.
For example, P7 correctly assumed that \CodeIn{SecureRandom} handles the secure seeding of random number generators.
In contrast with P8, P7's correct assumption lead him to propose a more succinct solution.



%\item Consult teammates as a strategy 

%Brings unwanted attention to our inserted vulnerability
%As P2, P7, and P8 explored the code pertaining to the SQL Injection vulnerability, they became curious as to why developers of the code would use Java's \texttt{Statement} instead of the presumably more secure \texttt{PreparedStatement} for sending queries to a Database Access Object.
%For this question, if participants made an attempt to find the answer, they also focused their attention on outside resources they could use to find the answer. 
%It seems most, if not all, of the questions in this category require information that existing tools may not be able to provide.

%For example, as P7 began assessing the vulnerability, he explored the code involved in the vulnerability with the goal of understanding what the code does. 
%He was hoping he could there would be library documentation (\textit{Is this library code?}) he could find and use to answer his question, however, upon further investigation realized the code was written by someone writing the software, a resource he would not be able to easily access.
%Along the same lines, P10 stated he would ask other developers about the code to learn what it does.
% P1 -- B3

% 

%%%%%%%%%%%% Application Context

\subsubsection{Application Context and Usage (9)\{9\}}\label{acu}
%#4.X

Unlike questions in Section \ref{cbf}, these questions refer to system-level concepts.
For instance, often while assessing the vulnerabilities, participants wanted to know what the code was being used for, whether it be testing, creating appointments with patients, or generating passwords.
\\

\noindent\emph{What is the context of this vulnerability/code? (4)} \\
\emph{Is this code used to test the program/functionality? (4)} \\
\emph{What is the method/variable used for in the program? (3)} \\
\emph{Will usage of this method change? (2)} \\
\emph{Is the method/variable ever being used? (2)} \\
\\

% B1, 2, 3 -- mostly 1(?)

% B1, 2, 3 -- mostly 2(?)
Participants tried to determine if the code in the Potential Path Traversal vulnerability was used to test the system. 
P2, P4, P9, and P10 asked whether the code they were examining occurred in classes that were only used to test the application. 

%Though all participants had experience coding in iTrust, and had some knowledge about the code base, many still encountered situations where they wanted to know the usage or context of a segment of code within the application. 


\textbf{Strategies and Assumptions:}
Participants were particularly interested in differentiating between two contexts --- test code and application code. 
%20:04
As P4 explained, test code does not ship with the product, so it is held to a different standard from a security perspective. 
To answer their questions about tests, participants sometimes used tools for traversing the call hierarchy; using these types of tools allowed them to narrow their search to only locations where the code of interest was being called.


Participants' strategies for this task were undermined by the FSB ``Bug Explorer'' view, because it obscured many of the usual cues participants would have used to differentiate between contexts.
In iTrust, tests are organized into a test package, which is separate from the application code. 
By default, the ``Bug Explorer'' view closes the package explorer and omits package names from the notification text.
Without visible package names or the package explorer, some participants were mislead.
For instance, P9 incorrectly inferred the code for Task 3 was contained within a test class before eventually correcting his mistake, 
``This one I would be more inclined to ignore, because it's a test method I believe... Wait no, it's not a test method. No, it's not.''
Had P9 not corrected his mistake, he would have misdiagnosed the error and ignored a true positive.




%\begin{itemize}
%	\item Determine  if the user has been authenticated or how the random num gen is used
%	\item Look for keyword indicators.  random password
%	\item Easy because in iTrust test can refer to a medical test or a jUnit test (Move that to here?)
%\end{itemize}


%%%%%%%%%%%% End-User Interaction

\subsubsection{End-User Interaction (8)\{3\}}
%#13.X

\label{eui}

Questions in this category deal with how end users might interact with the system or a particular part of the system. 
Some participants wanted to know whether users could access critical parts of the code and if measures were being taken to mitigate potentially malicious activity. 
For example, while assessing the Potential Path Traversal vulnerability, participants wanted to know whether the path is sanitized somewhere in the code before it is used.
\\

\noindent\emph{Is there input coming from the user? (4)} \\
\emph{Does the user have access to this code? (4)} \\
\emph{Does user input get validated/sanitized? (4)} 
\\

 
% seemed mostly a concern for B3, but also B1 and B4 for some
When assessing the Potential Path Traversal vulnerability, P1 and P6 wanted to know if the input was coming from the user along with whether the input was being validated in the event that the input did come from the user.
While working on the same task, four participants also asked whether end-user input reached the code being analyzed.



% B1, 3, 4 -- mostly 3

% user access
% B1
% P1, P6: all these test data generator so no user access (how did he get to this?)
% P2: vulnerability only exists if user can access this code (used call hierarchy)



\textbf{Strategies and Assumptions:}
For participants, answering their questions required manual inspection of the source code. 
For instance, P6 found a \CodeIn{Validator} method, which he manually inspected, to determine if it was doing input validation.
He incorrectly concluded that the \CodeIn{Validator} method adequately validated the data.

P2 used \textsc{call hierarchy} to trace end-user input; he assumed the vulnerability was a true positive if user input reached the vulnerable line.
P1 and P6 searched similarly and determined that because all the calls to the code of interest appeared to happen in methods called \CodeIn{testDataGenerator()}, the code was not vulnerable.


More generally, participants' strategies for answering questions about end-user interaction typically included strategies from other categories. 
In other words, participants gathered evidence by Locating Information (Section \ref{li}), examining Control Flow (Section \ref{cf}), retracing Data Flow (Section \ref{dsf}) information, and recalling information about the Code Background (Section \ref{cbf}). 
Participants successfully answered questions in this category when they successfully synthesized the results of these other efforts.





\subsection{Individuals}

\label{sec:results-i}
%#1.X

%%%%%%%%%%%% Developer Planning
\subsubsection{Developer Planning and Self-Reflection (8)\{14\}}
\label{dpr}
 
This category contains questions that participants asked about themselves.
The questions in this category involve the participants' relationship to the problem, rather than specifics of the code or the vulnerability notification.
\\

\noindent\emph{Do I understand? (3)} \\
\emph{What should I do first? (2)} \\
\emph{What was that again? (2)} \\
\emph{Is this worth my time? (2)} \\
\emph{Why do I care? (2)} \\
\emph{Have I seen this before? (1)} \\
\emph{Where am I in the code? (1)} 
\\

Participants most frequently asked if they understood the situation, whether it be the code, the notification, or a piece of documentation. 
For instance, as P6 started exploring the validity of the SQL Injection vulnerability, he wanted to know if he fully understood the notification before he started exploring, so he went back to reread the notification before investigating further.
These questions occurred in all four vulnerabilities.


\textbf{Strategies and Assumptions:}
Compared to other categories, the strategy and assumption analysis results in this category are sparse.
Although we asked participants to think-aloud, they seemed to resolve questions in this category internally. 


%%%%%%%%%%%% Understanding Concepts

\subsubsection{Understanding Concepts (7)\{6\}}\label{uc}
%#15.X

Some participants encountered unfamiliar terms and concepts in the code and vulnerability notifications.
For instance, while parsing the potential attacks listed in the notification for the Servlet Parameter vulnerability, some participants did not know what a CSRF token was.
\\

\noindent\emph{What is this concept? (6)} \\
\emph{How does this concept work? (4)} \\
\emph{What is the term for this concept? (2)}
\\

% what is this concept (6) -- P2, 5, 8, 10
% P2: what is path traversal --> clicked first link in FB
% P7/P8: what is CSRF token --> no link, wikipedia
% P4: what is servlet and how relates to client control --> no link (said would have linked some info on that)

For some vulnerability patterns, FSB links to resources that define relevant concepts.
Otherwise, information about concepts and terminology could be found online.
When asked what information he would like to see added to the notification for the Servlet Parameter vulnerability, which did not include any links, P4 noted he would have liked the notification to include links defining a servlet is and how it related to client control.


\textbf{Strategies and Assumptions:}
Participants' strategies for finding information about concepts included clicking the links provided by FSB.
For example, while assessing the Potential Path Traversal vulnerability, P2, unsure of what path traversal was, clicked a link, labeled ``path traversal attack,'' provided by FSB to get more information.
However, this strategy failed when the hyperlink text poorly described the links' contents.
Unable to determine the quality and type of information hidden behind FSB's links, some participants preferred to search the web for information about concepts.

If a link was not available or if its contents were unclear, participants went to the web to get more information.
While parsing the information provided for the Predictable Random vulnerability, P7 and P8 did not know what CSRF token was.
The notification for this vulnerability did not include links so they searched the web instead. 

We observed participants using several noteworthy sub-strategies while searching online.
To find information pertaining to their particular situation, several participants copied and pasted content directly from the FSB notification into their web browser.
Participants also demonstrated the simple, yet successful, strategy of iteratively refining their search terms. 
For example, after performing a search that failed to return relevant results, P1 added specificity to his search by adding the term `Java'.
Finally, we noticed some consistency in the strategies participants were using to find information about concepts --- several different participants used the exact same search terms. 
%\item Across participants, several used the exact same search terms.***


%\begin{itemize}
%	\item Search google for info on secure random
%	\item select wikipedia links for CSRF 
%	\item SO offline for maintenance for one participant
%	\end{itemize}



%%%%%%%%%%%% Confirming Expectations

\subsubsection{Confirming Expectations (4)\{1\}}
%#16.1

\label{ce}
% possibly could be put with developer planning/self-reflection OR code background and function?

A few participants wanted to be able to confirm whether the code accomplishes what they expected. 
The question asked in this category was, \textit{Is this doing what I expect it to?} 


\textbf{Strategies and Assumptions:}
We did not observe many overarching strategies or assumptions in this category, in part because participants rarely signaled to us when they were testing their expectations. 
When we did observe participants questioning their expectations, their strategies varied situationally.


\subsection{Problem Solving Support}
\label{sec:results-pss}
%%%%%%%%%%%% Resources
\subsubsection{Resources and Documentation (10)\{10\}}
%#6.X

\label{rd}
Many participants indicated they would use external resources and documentation to gain new perspectives on vulnerabilities.
For example, while assessing the Potential Path Traversal vulnerability, participants wanted to know what their team members would do or if they could provide any additional information about the vulnerability. 
\\

\noindent\emph{Can my team members/resources provide me with more information? (5)} \\
\emph{Where can I get more information? (5)} \\
\emph{What information is in the documentation? (5)} \\
\emph{How do resources prevent or resolve this? (5)} \\
\emph{Is this a reliable/trusted resource? (3)} \\
\emph{What type of information does this resource link me to? (2)}
\\
 
All ten participants had questions regarding the resources and documentation available to help them assess a given vulnerability. 
Even with the links to external resources provided by two of the notifications, participants still had questions about available resources. 
Some participants used the links provided by FSB to get more information about the vulnerability.
Participants who did not click the links in the notification had a few reasons for not doing so.
For some participants, the hyperlinked text was not descriptive enough for them to know what information the link was offering; others did not know if they could trust the information they found.

Some participants clicked FSB's links expecting one type of information, but finding another. 
For example, P2 clicked the first link, labeled ``WASC: Path Traversal,'' while trying to understand the Potential Path Traversal vulnerability hoping to find information on how to resolve the vulnerability.
When he did not see that information, he attempted another web search for the same information. 
A few participants did not know the links existed, so they typically used other strategies, such as searching the web.

Other participants expressed interest in consulting their team members. 
For example, when P10 had difficulty with the Potential Path Traversal vulnerability, he stated that he would normally ask his team members to explain how the code worked.
Presumably, the code's author could explain how the code was working, enabling the developer to proceed with fixing the vulnerability.


\textbf{Strategies and Assumptions:}
Participants' primary strategy involved consulting the code (i.e. variable and class names) along with its sparse comments.
Participants seemed to successfully use this information to understand basic code constructs (i.e. control structures, variable types, method calls, and which variables were being stored in which data structures).
However, these strategies sometimes failed to convey security-relevant semantic information.
Further, this strategy fell short when participants sought documentation for IDE tools or external APIs; such information was not readily available within the code itself. 

Supplementing their primary strategy, participants gathered additional information from web resources.
Additionally, participants described their plans to contact team members for help, although they could not do so within the confines of the study.

%\begin{itemize}
%	\item Touched on many of these in other strategy sections 
%	\item Strategies include clicking links in FSB
%	\item Searching (and refining searches) on the web
%	\item (teammates)
%	\item  read comments, self-documenting code - var/class names
%	\item read inline javadocs
%	\item search for the specific FSB code
%\end{itemize}


%%%%%%%%%%%% Understanding Interacting Tools

\subsubsection{Understanding and Interacting with Tools (8)\{9\}}
%#18.X

\label{uit}

Throughout the study participants interacted with a variety of tools including FSB, \textsc{call hierarchy}, and \textsc{find references}. 
While interacting with these tools, participants asked questions about how to access specific tools, how to use the tools, and how to interpret their output. 
\\

\noindent\emph{Why is the tool complaining? (3)} \\
\emph{Can I verify the information the tool provides? (3)} \\
\emph{What is the tool's confidence? (2)} \\
\emph{What is the tool output telling me? (1)} \\
\emph{What tool do I need for this? (1)} \\ 
\emph{How can I annotate that these strings have been escaped and the tool should ignore the warning? (1)}
\\

%[ACCESSIBILITY (4 letter word)]
Participants asked questions about accessing the tools needed to complete a certain task.
Participants sometimes sought information from a tool, but could not determine how to invoke the tool or possibly did not know which tool to use. 
The question, \emph{What tool do I need for this?} points to a common blocker for both novice and experienced developers, a lack of awareness~\cite{murphy-Hill2012fluency}.


\textbf{Strategies and Assumptions:}
We observed two types of strategies in this category, tool selection strategies and tool evaluation strategies. 
While selecting tools, participants often knew what functionality they wanted to achieve, but were unsure how to find a tool to achieve that functionality. For example, P2 knew he wanted to navigate to methods up the call hierarchy, but struggled to identify an appropriate tool. 
His tool selection strategy involved first Ctrl-hovering over the current method's name followed by right clicking the method name.
This strategy failed because the tool was not available in the Ctrl-hover menu and he failed to recognize the tool in the right-click menu.

Rather than search for the ideal tool, some participants opted to opportunistically invoke tools and evaluate the appropriateness of their output. Unfortunately, these strategies were susceptible to misinterpretations. For example, one participant opened, closed, and reopened the \textsc{call hierarchy} tool several times, unable to determine whether it was appropriate. 

When FSB failed to effectively communicate information about the location of defects to participants, they made assumptions.
For Task 3, P10 incorrectly assumed FSB was indicating an issue with the database access objects (DAOs), rather than the sanitization methods.
He probably made this assumption, because FSB placed its bug markers in the file containing the DAOs and not in their associated sanitization methods. 
Based on that assumption, he proposed adding a sanitization method to those objects, which is an incorrect fix.
Sanitization methods already existed in another class and just needed to be modified.


%\item Misinterpret tools output, whether it be FSB's notifications, severity rankings, or call hierarchy
%\item After reading the notification, relate its content back to the code


%%%%%%%%%%%% Vulnerability Severity/Ranking

\subsubsection{Vulnerability Severity and Ranking (5)\{4\}}
%#2.X

\label{bsr}

FSB estimates the severity of each vulnerability it encounters and reports those rankings to its users (Table \ref{table:vulnerabilities}). 
Participants asked questions while interpreting these rankings.
\\

\noindent\emph{How serious is this vulnerability? (2)} \\
\emph{How do the rankings compare? (2)} \\
\emph{What do the vulnerability rankings mean? (2)} \\
\emph{Are all these vulnerabilities the same severity? (1)}
\\
 
Most of these questions came from participants wanting to know more about the tool's method of ranking the vulnerabilities in the code.
For example, after completing the first task (Potential Path Traversal), P1 discovered the tool's rank, severity, and confidence reports. 
He noted how helpful the rankings seemed and included them in his assessment process for the following vulnerabilities.
As he began working through the final vulnerability (SQL Injection), he admitted that he did not understand the tool's metrics as well as he thought. 
He wasn't sure whether the rank (15) was high or low and if yellow was a ``good'' or ``bad'' color.
Some participants, like P6, did not notice any of the rankings until after completing all four sessions when the investigator asked about the tool's rankings.


\textbf{Strategies and Assumptions:}
Severity ratings typically help developers triage vulnerabilities.
Due to the limitations of our controlled study, we preselected the vulnerabilities and the order in which they would appear.
As a result, working with the severity rankings was not critical for participants to complete their tasks.
Therefore, we observed few assumptions and relatively shallow strategies in this category; some participants asked questions about the rankings, but most did not follow up with an investigation.
%%%%%%%%%%%% Notification Text

\subsubsection{Notification Text (6)\{3\}}\label{em}
%#14.X

FSB provided long and short descriptions of each vulnerability (Figure \ref{fig:environment}). 
Participants read and contemplated these notifications to guide their analysis.
\\

\noindent\emph{What does the notification text say? (5)} \\
\emph{What is the relationship between the notification text and the code? (2)} \\
\emph{What code caused this notification to appear (2)} 
\\

Beyond asking about the content of the notification, participants also asked questions about how to relate information contained in the notification back to the code. 
For example, the Predictable Random vulnerability notes that a predicable random value could lead to an attack when being used in a secure context. 
Many participants attempted to relate this piece of information back to the code by looking to see if anything about the code that suggested it is in a secure context. 
In this situation, the method containing the vulnerability was named \CodeIn{randomPassword()}, which suggested to participants that the code was in a secure context and therefore a vulnerability that should be resolved.


\textbf{Strategies and Assumptions:}
Participants' defect resolution strategies appeared to include reading portions of the notification text. 
The three participants (P3, P4, and P6) who reported the lowest familiarity with vulnerabilities 
started 11 of 12 tasks by immediately reading the notification text. 
Conversely, the participants (P5 and P7) who reported the most familiarity with vulnerabilities only started by reading the notification text for 2 of 8 tasks.

%what is the consequence
The distinctions between these two workflows affected how participants built hypotheses.
Low-familiarity participants built their initial hypothesis from the notification and tested that hypothesis against the code. 
On the other hand, high-familiarity participants used the notification to refine their already-formed hypotheses. 
It remains an open question whether tool notifications currently support one of these workflows more than the other.
The prominence of explanatory text and reference information over resolution shortcuts might suggest FSB caters to the hypothesis-building novices.
Either way, the presence of two distinct workflows suggests tools should support both. 

Participants' strategies also varied in terms of how much of the notification they read.
Some participants read the entirety of the message before proceeding, whereas others only read the short descriptions. 
Several participants read the visible parts of the long description, but neglected to scroll further to reveal the rest of the message.
Often, this lead to problems. 
For instance, P3 struggled with the Predictable Random vulnerability because he initially failed to find documentation for \texttt{SecureRandom}.
P3 started the task by reading only the first half of the long description.
After finally finding the documentation online and completing the task, the interviewer directed his attention to the overlooked second half of the long description.
P3 read the rest of the description and realized it contained the information he sought,
``I didn't scroll down that far. I see it even has a link to generating strong random number. I could have clicked on this link.'' 

%\begin{itemize}
%	\item Read the notification text
%	\item mentioned relating content back in interacting with tools
%	\item Participants found unclear sentences distracting
%\end{itemize}

%\section{Assumptions}
%\label{sec:assumptions}

%External library correctness
%-> App context and usage

%-> tools 
%P9 T1 issue relates to SQL file


%-> data storage and flow


%Topic: Code functionality
%General description of these types of assumptions
%Give an example of this assumption
%How does this contribute to overall defect resolution!


%Report the breakdown by count / participant / task?
%Or.... just focus on the types? 
%Types of assumptions (informal categorization) ad-hoc organization


\section{Discussion}
\label{sec:discussion}
In this section we discuss the implications of our work.

\subsection{Flow Navigation}
\label{flowNav}
When iTrust performed security-sensitive operations, participants wanted to determine if data originated from a malicious source
by tracing program flow.
Similarly, given data from the user, participants were interested in determining how it was used in the application and whether it was sanitized before being passed to a sensitive operation. Questions related to these tasks appear in four different categories (Sections \ref{li}, \ref{cf}, \ref{dsf}, \ref{eui}).
We observed participants using three strategies to answer program flow questions,
strategies that were useful, yet potentially error-prone.

First, when participants asked whether data comes from the user (\emph{a user-facing source}), 
and thus cannot be trusted, or if untrusted data is being used in a sensitive operation,
participants would navigate through chains of method invocations.
When participants navigated through chains of method invocations,
they were forced to choose between different tools, where each tool
had specific advantages and disadvantages.
Lightweight tools, such as \textsc{find} and \textsc{mark occurrences}, could be easily invoked and the output
easily interpreted, but they often required multiple invocations and sometimes returned 
partial or irrelevant information.
For example, using \textsc{mark occurrences} on a method declaration highlights all invocations of the method 
within the containing file, but it does not indicate invocations in other files.
%also doesn't allow for systematic investigation (you can miss some highlights)
On the other hand, heavyweight tools, such as \textsc{call hierarchy} and \textsc{find references}, 
return method invocations made from anywhere in the source code, but were slower and clumsier for participants.
% are undermined by barriers to invocation~\cite{johnson2013don}
Moreover, even heavyweight tools do not return all invocations when looking for tainted data sources;
for instance, \textsc{call hierarchy} does not indicate when methods are being called from outside the system
by a framework.
%, and does not allow developers to trace the call structure while also tracking where specific parameters are set.

Second, when participants asked whether a data source was user-facing,
participants would make inferences based on class names.
For instance, any class that started with \texttt{Test} participants assumed was as JUnit test case,
and thus was not user-facing, and therefore not a potential source of tainted data.
When participants made inferences based on class names,
their inferences were generally correct that the class name accurately described
its role.
However, this strategy
%This strategy does not scale particularly well and 
fails in situations where the word ``Test'' is overloaded;
this happens in iTrust where ``Test'' can also refer to 
a medical laboratory test.
%, or if they accidentally missed one

Third, a common strategy for
participants was to rely on their existing knowledge of sensitive operations and data sources in the application.
When participants relied on existing knowledge of sensitive operations and data sources,
such reliance may be failure-prone whenever the code has been changed without their knowledge.
Indeed, prior research suggests that developers are 
less knowledgeable about unstable code~\cite{fritz2014degree}. 
Additionally, when a developer only contributes to a portion of the system, as is often the case in the open source community~\cite{mockus2002open}, he may be unable to reason about the system-wide implications of a change. 

Much like work that examines more general programming tasks \cite{latoza2010hard}, we observed that participants would have benefited from better program flow navigation tools while investigating security vulnerabilities.
Although researchers have proposed enhanced tools to visualize call graphs~\cite{latoza2011visualizing} and trace control flow to its origin~\cite{barnett2014getMeHere},
in a security context, these tools share the same limitations as the existing heavyweight tools.
Existing tools like CodeSonar~\cite{CodeSonar} and Coverity provide source-to-sink notifications for analyzing security
vulnerabilities, but take control away from the programmer by forcing the developer into a tool-dictated
workflow.


We envision a new tool that helps developers reason about control flow and data flow simultaneously,
by combining the strengths of existing heavy and lightweight tools.
We imagine such a tool could use existing heavyweight program analysis techniques, but still
use a lightweight user interface.
For example, such a tool might use a full-program, call hierarchy analysis technique in the back end,
but use a \textsc{mark occurrences}-like user interface on the front end.
To indicate calls from outside the current class, additional lightweight notifications would be needed.
Such a tool could support both lightweight and systematic investigation of the flow of 
potentially tainted data.



%Such a tool could adapt a precise, yet heavyweight, control flow navigation tool by reducing its barriers to invocation, a technique successfully demonstrated by \textsc{Spyglass}~\cite{viriyakattiyaporn2010spyglass}.
%Further, the tool could allow developers to specify specific parameters to trace and display information about where those values are modified.
%Finally, the tool could alert developers to the possibility that some calls might originate from outside the system and that tainted user data may enter the system through other channels.

\subsection{Structured Vulnerability Notifications}
\label{structuredNotifications}
FSB provided explanatory notifications of potential vulnerabilities.
However, to completely resolve vulnerabilities,
participants performed many cognitively demanding tasks beyond simply locating the vulnerability and reading the notification, 
as is evidenced by the breadth of questions they asked. 
To resolve potential vulnerabilities, we observed participants deploying a mix of several high-level strategies including: 
inspecting the code;
navigating to other relevant areas of the code; 
comparing the vulnerability to previous vulnerabilities; 
consulting documentation and other resources; 
weighing existing knowledge against information in the notification; 
and reasoning about the feasibility of all the possible attacks. 
Yet, these strategies were limited in three respects.

Participants used error-prone strategies even when more reliable tools and strategies were available. 
%Reworked P5
For example, in Section \ref{rd}, we noted that participants, unaware of the relevant hyperlinks embedded within the notification text, searched for links to external resources using web search tools. 
The web searches often returned irrelevant results. 
However, when the interviewer pointed out the embedded links after the session, participants stated that they probably should have clicked them. 

Second, even after choosing an effective strategy, participants were often unaware of which tools to use to execute the strategy.
For example, while assessing the Servlet Parameter vulnerability, participants wanted to determine whether certain input parameters were ever validated, but were not aware of any tools to assist in this process.
Previous research suggests that both novice and experienced developers face problems of tool awareness~\cite{murphy-Hill2012fluency}.

Third, regardless of the strategies and tools participants used, they had to manually track their progress on each task.
For example, the Servlet Parameter vulnerability involved twelve tainted parameters and introduced the possibility of several types of attacks. 
Participants had to reason about each of those attacks individually and remember which attacks they had ruled out.
In a more general programming context, researchers have warned about the risks of burdening developers' memories with too many concurrent tasks 
--- overburdening developers' attentive memories can result in \emph{concentration failure} and \emph{limit failure}~\cite{parnin2012programmer}.

%Wordy start. Maybe phrase as an approach that makes strategies concrete
%Clarify, establish, 
%%explicating
We envision an approach that addresses these limitations by explicating developers' strategies in the form of hierarchically structured checklists.
Previous research suggests that checklists can effectively guide developers~\cite{phang2009triaging}.
We propose a structure that contains hierarchical, customizable tasks for each type of notification.
For example, the structure would contain high-level tasks, such as ``Determine which attacks are feasible,'' and subsequently more actionable nested subtasks, such as ``Determine if a SQL injection attack is feasible'' or ``Determine if an XSS attack is feasible.''
This structure would also include a checklist-like feature that allows users to save the state of their interaction with a particular notification --- for example, checking off which attack vectors they have already ruled out --- diminishing the risk of \emph{concentration failure} and \emph{limit failure}.
Additionally, each task could include links to resources that relate specifically to that task and tool suggestions that could help developers complete the task.

\subsection{Context-Informed Web Search}
Accessing web resources was an important element of participants' strategies across several categories (Section \ref{pupa}, Section \ref{uafa}, Section \ref{uc}, Section \ref{rd}).
To find success, participants sought information that was scattered around different sites.
Depending on the task and an individual's approach, participants found critical clues hidden on StackOverflow, official documentation pages, and personal blogs, for instance. 

To reach these helpful web resources, participants either followed the links that FSB had curated, or used an online search engine. 
Both of these approaches are failure-prone.
However, by drawing inspiration from the positive aspects of each of these approaches, we will propose a new tool-assisted approach for gathering resources from the web while diagnosing a static analysis defects. 
We will refer to this approach as \textit{context-informed web search}.

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{Images/FSBRefs}
	\caption{Reference links provided by FSB for Path Traversal vulnerability}
	\label{fig:links} 
\end{figure}


FSB includes links to web resources in its description of some defects under the header ``References'' (Figure \ref{fig:links}).
%A practice common to many such static analysis tools???
FSB's designers assumedly deem these references relevant and helpful, and, when references to the right types of information were available, participants tended to use them.
Unfortunately, the links in each references section cover a limited number of topics.
As in the example depicted by Figure \ref{fig:links}, the reference material might describe the defect and how to exploit it, but not provide code examples for remedies.
In practice participants sought information and visited sites beyond what was available in the finite reference sections.
In summary, the references encapsulate the tool \textit{designer's} expertise and knowledge of a specific defect pattern, but are not tailored to the user's needs.

%Other limitations of fsb links
%Can't assess their credibility, no preview of the contents. 
%Appear off-screen, participants didn't scroll down
%Little indication of what information each link promised
%pro: Perfectly suited to the defect the tool was detecting. 

Participants also used search engines to locate web resources, sometimes as a primary means, other times after having exhausted the FSB links.
With this approach, participants had to sift through long lists of irrelevant results to find useful information.
As described in Section \ref{uc}, some participants iteratively refined their search terms to filter out as many irrelevant results as possible.
Others simply tested link after link until they found something useful or gave up.

The two approaches for accessing web resources described so far (using tool links and performing a search) fail in complementary ways. 
The tool's list of links only cover a narrow set of topics, with each link highly relevant to the defect reported. 
Conversely, search engines over-approximate the set of relevant resources, but cover far more topics of interest. 

We envision a new way for developers to access web resources while resolving defects with static analysis, \textit{context-informed web search}. This approach improves on existing approaches by combining the breadth of web search with the relevance afforded by a tool's contextual awareness.
Users would perform a \textit{context-informed web search} just as they would any other web search, but enter their query into a specialized search engine, rather than a general-purpose search engine.
The specialized search engine would work in tandem with the developers' static analysis tool and would start by fetching results just like a general-purpose search engine.
Before returning those results to the user, the specialized search engine would query the static analysis tool for details about the developers context --- information the tool has already computed in order to detect defects.
Finally, the specialized search engine would only display context-relevant results.
%also look to see if links provided by toolsmith pop up

Consider, for example, a developer who searches for `secure random number.'
A general-purpose search engine would return results targeted at Ruby, Javascript, Android, and Java developers.
The specialized search engine could conclude from the static analysis tool that the developer was using Java and importing java.util.Random and filter out irrelevant results pertaining to other languages.

%Successful participants informally implemented this strategy by extracting verbatim text from the notification to form their web search phrases. 
%Basically, copying and pasting the short description or snippets from the long description.
%This helped to ensure results were relevant to that specific issue, but misses relevant resources that might be (other tools or other versions of the same tool)
%Search had no knowledge of code or libraries and result quality depended on participants' ability to select the correct text.
%Formalize that approach

%Info foraging.
%disorientation stuff??
%Common behavior was search
%Security implications of a given strategy varied depending on the context and type of vulnerability. 
%envision context-aware tools that support context-aware strategies

\section{Related Work}
\label{sec:rw}

We have organized the related work into three subsections. 
Section \ref{evaluation} outlines some of the current approaches researchers use to evaluate security tools, Section \ref{questions} references other studies that have explored developers' information needs, and Section \ref{strategies} relates our work to the other work on strategies.

\subsection{Evaluating Security Tools}
\label{evaluation}
Using a variety of metrics, many studies have assessed the effectiveness of the security tools developers use to find and remove vulnerabilities from their code~\cite{martin2005finding, austin2011one, livshits2005finding}.  

Much research has evaluated the effectiveness of tools based on their false positive rates and how many vulnerabilities they detect~\cite{jovanovic2006pixy, austin2011one, dukes2013case}. 
For instance, Jovanovic and colleagues evaluate their tool, \textsc{Pixy}, a static analysis tool that detects cross-site scripting vulnerabilities in PHP web applications~\cite{jovanovic2006pixy}. 
They considered \textsc{Pixy} effective because of its low false positive rate (50\%) and its ability to find vulnerabilities previously unknown. 
Similarly, Livshits and Lam evaluated their own approach to security-oriented static analysis, which creates static analyzers based on inputs from the user~\cite{livshits2005finding}. 
They also found their tool to be effective because it had a low false positive rate. 

Austin and Williams compared the effectiveness of four existing techniques for discovering security vulnerabilities: systematic and exploratory manual  penetration testing, static analysis, and automated penetration testing~\cite{austin2011one}. 
Comparing the four approaches based on number of vulnerabilities found, false positive rate, and efficiency, they reported that no one technique was capable of discovering every type of vulnerability. 

Dukes and colleagues conducted a case study comparing static analysis and manual testing vulnerability-finding techniques~\cite{dukes2013case}. 
They found combining manual testing and static analysis was most effective, because it located the most vulnerabilities.

These studies use various measures of effectiveness, such as false positive rates or vulnerabilities found by a tool, but none focus on how developers interact with the tool. 
Further, these studies do not evaluate whether the tools address developers' information needs. 
Unlike existing studies, our study examines a security tool through the lens of developers' information needs and, accordingly, provides a novel framework for evaluating security tools.

\subsection{Information Needs Studies}
\label{questions}
Several studies have explored developers' information needs outside the context of security.
Similar to our work, some existing studies determine these needs by focusing on the questions developers ask~\cite{latoza2010hard, latoza2010developers, Ko:2007:information, Sillito:2006questions}.
These three studies explore the questions developers ask while performing general programming tasks.
In contrast to previous studies, our study focuses specifically on the information needs of developers while performing a more specific task, assessing security vulnerabilities.
Unsurprisingly, some of the questions previously identified as general programming questions also occur while developers assess security vulnerabilities (e.g., Sections \ref{cf} and \ref{dsf}).

Much of the work on answering developer questions has occurred in the last decade. 
LaToza and Myers surveyed professional software developers to understand the questions developers ask during their daily coding activities, focusing on the hard to answer questions~\cite{latoza2010hard}. 
Furthermore, after observing developers in a lab study, they discovered that the questions developers ask tend to be questions revolving around searching through the code for target statements or reachability questions~\cite{latoza2010developers}. 
Ko and Myers developed \textsc{Whyline}, a tool meant to ease the process of debugging code by helping answer ``why did'' and ``why didn't'' questions~\cite{ko2004designing}. 
They found that developers were able to complete more debugging tasks while using their tool than they could without it.
Fritz and Murphy developed a model and prototype tool to assist developers with answering the questions they want to ask based on interviews they conducted~\cite{fritz2010using}.

%Questions programmers ask during software evolution tasks??

\subsection{Defect Resolution Approaches}
\label{strategies}
Prior work has noted the importance of strategies.
In their inspirational work, Bhavnani and John observed that knowledge of tasks and tools for complex computer applications such as CAD were insufficient for developers to be efficient; they found that users needed to learn good strategies~\cite{Bhavnani2000}. 
Additionally, they argue that the identification of efficient strategies should be a key research goal. 
Our work furthers progress toward that goal by identifying successful strategies for resolving security vulnerabilities.

Similarly, Katz and Anderson noted the importance of good strategies. 
They found that a developer's choice of bug-location strategy affects his or her ability to assess the correctness of a line of code~\cite{Katz:1987}.
Our work extends that of Katz and Anderson by focusing on the defect resolution process after a potential bug has been located.

Several studies have explored the effects of strategies and assumptions in end-user programming environments.
Grigoreanu and colleagues examined gender differences in debugging strategies for spreadsheet end-user programmers~\cite{Grigoreanu:2012:sense, Grigoreanu:2009}. 
Through a think-aloud study, they found that women and men employed different strategies. 
For example, women tended to use comprehensive information processing styles, where they overview the task before making changes; in contrast, men tended to selectively process information.
Gross and colleagues conducted an exploratory study in which end-user programmers were asked to find and modify code for specific functionality with unfamiliar programs, which they classified into models~\cite{Gross:2010}.
Ko and colleagues categorized six types of learning barriers faced by end-user programmers~\cite{Ko:2004:barriers}.
They discussed how end-user programmers can overcome learning barriers by making simplifying assumptions, but incorrect assumptions often lead to errors.
We are similarly interested in strategies and assumptions.
In contrast to the prior work, we focus on the domain of security vulnerabilities rather than end-user programming environments.


%Romero and colleagues investigated, through virtual and textual-based views, how developers represented high-level and low-level debugging strategies in these software development environments.  
%They found that changes in the explicit representation of the software environment influenced the choice of strategies developers used in solving the task~\cite{Romero2007}.

%Lieber and colleagues evaluate an IDE extension for visualizing run-time behavior, Theseus~\cite{Lieber:2014:theseus}.
%In their work, they note that minor changes to the IDE's user interface affected noticeable changes to developers' strategies.



\section{Threats to Validity}
\label{limits}
In this section we discuss the internal and external threats to the validity of our study.

%Internal
We faced the internal threat of recording questions that participants asked because they lacked a basic familiarity with the study environment. 
We took two steps to mitigate this threat.
First, we required participants to have experience working on iTrust.
Second, at the  beginning of each session, we briefed participants on FSB and the development environment. 
During these briefing sessions, we gave participants the opportunity to ask questions about the environment and study setup, though we cannot say for certain that participants asked all the questions they had at that time.

Thus, some of the questions we identified may reflect participants' initial unfamiliarity with the study environment and FSB.
Since we are interested broadly in developers' information needs, the initial questions they ask about a new tool and environment still are an important subset to capture.

%External
Because this study was conducted in a controlled environment rather than an industrial development setting, our results also face a threat to their external validity. 
Though we cannot and do not claim that we have identified a comprehensive categorization of all security-related questions all developers might ask, we have made several efforts to mitigate this threat.
First, we included both students and professionals in our sample, because developers with more or less experience might ask different questions. 
Further, participants were equipped with FSB, a representative open source static analysis tool with respect to its user interface.
Finally, we chose iTrust, an industrial-scale open-source project as our subject application.

Relatedly, participants may have spent an unrealistic amount of time (either too much or too little) on each task due to working outside their normal work environment.
To counteract this threat, we did not restrict the amount of time alloted for each task.
Further, whenever a participant asked the interviewer what to do next, the interviewer provided minimal guidance, typically prompting the participant to proceed as she would in her normal work environment.


\section{Conclusion}
\label{sec:concl}
This paper reported on a study that explored how developers resolve security defects while using static analysis.
During our study, we asked ten software developers to describe their thoughts as they assessed potential security vulnerabilities in iTrust, a security-critical web application.
We presented the results of our study as a categorization of questions and a catalog of strategies for answering those questions.
This work advocates for tools that that not only detect vulnerabilities, but also help developers actually resolve those vulnerabilities.
Our findings have several implications for the design of static analysis tools.
Most broadly, tools should support effective strategies and provide information that aligns with the information needs we have identified.
In particular, our results suggest that tools should help developers, among other things, search for relevant web resources.


% use section* for acknowledgment
\section*{Acknowledgments}

We would like to thank our study participants. 
Special thanks to Xi Ge, Anthony Elliott, Emma Laperruque, and the Developer Liberation Front\footnote{\blind{\url{research.csc.ncsu.edu/dlf/}}} for their assistance. 
This material is based upon work supported by the National Science Foundation under grant numbers 1318323 and DGE--0946818.


% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


\appendices
\section{Recruitment Email}
Hi [Name],

My name is Justin Smith. I am a PhD student working with Dr. Murphy-Hill on doing a study with iTrust.
I am looking for students who have worked on this system in the past. Participation in this study will help
improve the design of security related software engineering tools.

The study will take approximately 45 -- 60 minutes to complete. Participants must perform the study at
NC State University, Room [TBD]. Familiarity with iTrust is required.

If you have any questions about the study or would like to schedule a time to participate, please respond
to me at this email address (jssmit11@ncsu.edu).
Participants must be 18 years of age or older.

\noindent Thanks!

\noindent Justin Smith 

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{Procedure}

\textbf{Introductory Script:} This experiment is designed to evaluate how you approach security vulnerabilities. This session
will be recorded using screen and audio capture software. I will present you with some code that
FindBugs has analyzed and ask you to explain what is going on.

This experiment is not designed to test your ability as a developer. Instead, we are attempting to
understand how you approach code vulnerabilities. During the experiment, you can use any web
resource. I have opened a web browser, which you are welcome to use at any point.

For the purposes of this experiment, imagine that you are in charge of security for iTrust, which
is nearing release. You must justify any proposed code changes that you make. Currently, the
software may contain security vulnerabilities. FindBugs has been configured to direct you to 4
areas of concern. For each area, Ill ask you about 10 questions.

Do you have any questions before we begin?

1) Navigate to first warning message

2) Read through the code/warning message

3) Try to think aloud. So, say any questions or thoughts that cross your mind regardless of
how relevant you think they are. 

\textbf{Experimental Questions:} 
\begin{itemize}
\item Can you explain what this warning is trying to tell you?

\item What are you exploring/trying to figure out right now?

\item What information do you need to proceed?

\item For the sake of time, explain to me what you would keep doing?

\item Would you normally do this in your work?

\item How does the wording effect the process?

\item Based on your understanding of this error message, what is the percentage likelihood you would modify this section of the code?

\item How would you fix the problem? Where would you start?

\item On a scale of 1-5, how confident are you in your understanding of this error message?

\item On a scale of 1-5, how confident are you that you are making the correct judgment?

\item What part of the message is most helpful?

\item What information would you like to see added to the error message?

\item Look at the error message one last time. Is there any information that you initially disregarded?

\item Anything else I should know?
\end{itemize}


\textbf{Post-Experiment Questions:}
\begin{itemize}
\item What is your current job title (if student, indicate so here)
\item How many years have you been programming?
\item How many years of professional programming experience do you have?
\item Over the last year, about how many hours per week would you say you spend programming, on
average?
\item When programming, do you typically use security tools? Y/N
\begin{itemize}
	\item If Y, Which tool(s) do you use? Why do you use these security tool?
	\item If N, can you tell me the reasons why you don't use security tools?
\end{itemize}
\item On a scale form 1 to 5, how familiar are you with security vulnerabilities?
(1 = not at all, to 5 = very familiar)
\item In general how effectively did the FindBugs communicate information to you? What did you or didnt you like?
\item What security related questions could the tool answer better?
\end{itemize}

\bibliographystyle{abbrv}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{iTrustInterviews}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)


% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
% or if you just want to reserve a space for a photo:

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Headshots/Justin}}]{Justin Smith}
	Justin is a PhD student at North Carolina State University. His research interests include human-computer interaction, software engineering, and security tools. 
	Contact him at jssmit11@ncsu.edu; 
	\url{http://www4.ncsu.edu/~jssmit11}
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Headshots/Brittany}}]{Brittany Johnson}
	Brittany is a PhD candidate at North Carolina State University. Her research interests are at the intersection of human-computer interaction, software engineering, and machine learning. She holds a B.A. in Computer Science from the College of Charleston. 
	Contact her at brittany\_johnson@ncsu.edu; 
	\url{http://www4.ncsu.edu/~bijohnso}
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Headshots/Emerson}}]{Emerson Murphy-Hill}
	Emerson is an associate professor at North Carolina State University. His research interests include human-computer interaction and software tools. He holds a Ph.D. in Computer Science from Portland State University. 
	Contact him at emerson@csc.ncsu.edu; \url{https://people.engr.ncsu.edu/ermurph3/}
	
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Headshots/Bill}}]{Bill Chu}
	Bill Chu is  Professor of Software and Information Systems at University of North Carolina at Charlotte. His research interest is in software security. He received  Ph.D. in Computer Science from the University of Maryland at College Park. 
	Contact him at billchu@uncc.edu
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Headshots/Heather}}]{Heather Ricter Lipford}
	Heather Richter Lipford is an Associate Professor at the University of
	North Carolina at Charlotte. Her research interests are in usable
	security and privacy. She holds a Ph.D. from the Georgia Institute of
	Technology. 
	Contact her at Heather.Lipford@uncc.edu;
	\url{http://webpages.uncc.edu/richter}
\end{IEEEbiography}

%% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%	Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage


% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}




% that's all folks
\end{document}


